<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">

<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Anjhon">


    <meta name="subtitle" content="小安">


    <meta name="description" content="佛系分享">



<title>神经网络 | Anjhon</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    





    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    





    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        
		src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/unpacked/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.1.1"></head>
<body>

	
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Anjhon</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">博文</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Anjhon</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">博文</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">展开全部</a>
        <a onclick="go_top()">回到顶部</a>
        <a onclick="go_bottom()">下到底部</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "折叠起来"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "展开全部"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">神经网络</h1>
            
                <div class="post-meta">
                    <br>
                    
                        作者: <a itemprop="author" rel="author" href="/">&nbsp;&nbsp;Anjhon</a>
                    

                    
                        <p class="post-time">
                        发表: <a href="#">&nbsp;&nbsp;2019-07-02</a>
                        </p>
                    
                    
                        <p class="post-category">
                    分类:
                            
                                <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">&nbsp;&nbsp;深度学习</a>
                            
                            </p>
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>本文整理自:</p>
<ul>
<li><a href="https://www.cnblogs.com/subconscious/p/5058741.html" target="_blank" rel="noopener">神经网络浅讲：从神经元到深度学习</a></li>
</ul>
<h1 id="一-生物神经网络"><a href="#一-生物神经网络" class="headerlink" title="一: 生物神经网络"></a>一: 生物神经网络</h1><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>一个神经元通常具有多个<strong>树突</strong>，主要用来接受传入信息；而<strong>轴突</strong>只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“<strong>突触</strong>”。</p>
<p><img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5nxyrkduj20b206ldgd.jpg" alt="神经元.png"></p>
<br>



<h1 id="二-人工神经网络-ANN"><a href="#二-人工神经网络-ANN" class="headerlink" title="二: 人工神经网络(ANN)"></a>二: 人工神经网络(ANN)</h1><h2 id="一-神经元模型MP"><a href="#一-神经元模型MP" class="headerlink" title="(一): 神经元模型MP"></a>(一): 神经元模型MP</h2><p>1943年，心理学家McCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型MP。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5nyhu64yj20ku0c53yx.jpg" alt="MP模型.png" style="zoom:67%;" />



<p>神经元模型是一个包含输入，输出与计算功能的模型。</p>
<p>连接是神经元中最重要的东西。每一个连接上都有一个权重。在神经元模型里，每个有向箭头表示的是值的加权传递。</p>
<p>一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。</p>
<p><strong>神经元的计算</strong></p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5nyymumxj20of0d1aai.jpg" alt="神经元计算.png" style="zoom:67%;" />



<p>可见z是在输入和权值的线性加权和叠加了一个<strong>函数g</strong>的值。在MP模型里，函数g是sgn函数，也就是取符号函数。这个函数当输入大于0时，输出1，否则输出0。</p>
<p>MP模型中，权重的值都是预先设置的，因此不能学习。</p>
<h2 id="二-单层神经网络"><a href="#二-单层神经网络" class="headerlink" title="(二):单层神经网络"></a>(二):单层神经网络</h2><p>1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字–“感知器”（Perceptron）</p>
<p>在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5nzdqs3yj20oy0h33zg.jpg" alt="单层神经网络.png" style="zoom:67%;" />

<p>与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个<strong>逻辑回归</strong>模型，可以做线性分类任务。</p>
<h2 id="三-两层神经网络"><a href="#三-两层神经网络" class="headerlink" title="(三): 两层神经网络"></a>(三): 两层神经网络</h2><p>两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。我们扩展上节的单层神经网络，在右边新加一个层次（只含有一个节点）。</p>
<p><strong>两层神经网络(中间层计算)</strong></p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o05m8nhj20ll0eujse.jpg" alt="两层神经网络(中间层计算).png" style="zoom:67%;" />



<p><strong>两层神经网络（输出层计算）</strong></p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o0j6e0jj20k30dj0td.jpg" alt="两层神经网络（输出层计算）.png" style="zoom:67%;" />







<p>在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o0v3kcxj20j20mn3zt.jpg" alt="两层神经网络（考虑偏置节点）.png" style="zoom:67%;" />





<p>在两层神经网络中，我们不再使用sgn函数作为函数g，而是使用平滑函数sigmoid作为函数g。我们把函数g也称作<strong>激活函数（active function）</strong>。</p>
<p>面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o1axdqfj20gm0g8q3r.jpg" alt="两层神经网络（决策分界）.png" style="zoom:67%;" />

<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o1k8qjvj20gm0g8aer.jpg" alt="两层神经网络（空间变换）.png" style="zoom:67%;" />

<p>可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。</p>
<p>矩阵和向量相乘，本质上就是对向量的坐标空间进行一个变换。因此，隐藏层的参数矩阵的作用就是使得数据的原始坐标空间从线性不可分，转换成了线性可分。</p>
<p>在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。</p>
<p>如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做Grid Search（网格搜索）。</p>
<p>机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。这就引出我们的损失函数</p>
<p>如何优化参数，能够让损失函数的值最小?</p>
<p>一般来说解决这个优化问题使用的是<strong>梯度下降</strong>算法。梯度下降算法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。</p>
<p>在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用<strong>反向传播</strong>算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。</p>
<p><strong>反向传播算法</strong></p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o1zjqfhj20j20ib755.jpg" alt="反向传播算法.png" style="zoom:67%;" />









<h2 id="四-多层神经网络-深度神经网络DNN"><a href="#四-多层神经网络-深度神经网络DNN" class="headerlink" title="(四): 多层神经网络(深度神经网络DNN)"></a>(四): 多层神经网络(深度神经网络DNN)</h2><p>在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o2dmthmj20r20hl0u3.jpg" alt="多层神经网络.png" style="zoom:67%;" />



<p>多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。</p>
<p>多层神经网络中的参数</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o2t1id9j20ub0o1tbg.jpg" alt="多层神经网络（较多参数）.png" style="zoom:50%;" />

<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o31lx43j20xf0m9mzu.jpg" alt="多层神经网络（更深的层次）.png" style="zoom:50%;" />

<p>虽然参数数量仍然是33，但却有4个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。</p>
<p>与两层层神经网络不同。多层神经网络中的层数增加了很多。</p>
<p>增加更多的层次有什么好处？<strong>更深入的表示特征，以及更强的函数模拟能力。</strong></p>
<p>更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。</p>
<p><strong>通过研究发现，在参数数量一样的情况下，更深的网络往往具有比浅层的网络更好的识别效率。</strong></p>
<p>在单层神经网络时，我们使用的激活函数是sgn函数。到了两层神经网络时，我们使用的最多的是sigmoid函数。而到了多层神经网络时，通过一系列的研究发现，ReLU函数在训练多层神经网络时，更容易收敛，并且预测性能更好。</p>
<p>三起三落的神经网络</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o3i09agj21in0tpjvk.jpg" alt="三起三落的神经网络.png" style="zoom:67%;" />







<p>从单层神经网络，到两层神经网络，再到多层神经网络，下图说明了，随着网络层数的增加，以及激活函数的调整，神经网络所能拟合的决策分界平面的能力。</p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o3wu4scj21go0yzdjx.jpg" alt="表示能力不断增强.png" style="zoom:67%;" />







<p><strong>神经网络的类别</strong></p>
<img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gn5o47x2bhj21en0mfgo1.jpg" alt="神经网络的类别.png" style="zoom:67%;" />
        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>文章作者:</span>
                        <span>Anjhon</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>文章地址:</span>
                        <span><a href="https://anjhon1994.github.io/2019/07/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></span>
                    </p>
                
                
                
                     <p class="copyright-item">
                         <span>灵魂拷问:</span>
                         <span>Do you believe in <strong>DESTINY<strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>文章标签:</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">▼ 深度学习</a>
                    
                        <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">▼ 神经网络</a>
                    
                        <a href="/tags/DNN/">▼ DNN</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">【返回上一层】</a>
                <span>· </span>
                <a href="/">【去往首页】</a>
            </div>
        </section>
        <section class="post-nav">
            	
                <a class="prev" rel="prev" href="/2019/07/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">上一篇：循环神经网络</a>
            
            
            <a class="next" rel="next" href="/2019/07/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">下一篇：特征工程</a>
            
			<br>

        </section>


		<br>
		
		
			<span>留下你的痕迹😀</span>
			<section id="comments" class="comments">
			  <style>
				.comments{margin:10px;padding:10px;background:#fff;bordercolor:0,0,0}
				@media screen and (max-width:900px){.comments{margin:auto;padding:20px;background:#fff;bordercolor:0,0,0}}
			  </style>
			  <div id="vcomment" class="comment"></div> 
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script src="https://cdnjs.loli.net/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
    var notify = 'false' == true ? true : false;
    var verify = 'false' == true ? true : false;
    new Valine({
        av: AV,
        el: '#vcomment',
        notify: notify,
        app_id: "d8Xy9CoRkV8wkjgNsf6IRqfe-gzGzoHsz",
        app_key: "ePiIX7dqVFpzeKkr4T1ixiah",
        placeholder: "🎈🎈🎈 Just say say ...",
        avatar:"robohash",

		
		
		
    });
</script>

			</section>
		
		


    </article>
</div>





			
        </div>
		
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 
		Anjhon | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a>
		
		
		
		
		</span>
    </div>
</footer>

    </div>
	


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/ Relative)","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":180,"height":350},"mobile":{"show":false},"react":{"opacityDefault":0.7}});</script></body>
</html>
