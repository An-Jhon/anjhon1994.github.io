<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Anjhon">


    <meta name="subtitle" content="小安">


    <meta name="description" content="没有做不到的事,只是看你想不想做">



<title>sklearn - 岭回归(Ridge)和套索回归(Lasso) | Anjhon&#39;s Blog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.1.1"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Anjhon&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">首页</a>
                
                    <a class="menu-item" href="/category">归档</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
                    <a class="menu-item" href="/about">时间线</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Anjhon&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">首页</a>
                
                    <a class="menu-item" href="/category">归档</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
                    <a class="menu-item" href="/about">时间线</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">sklearn - 岭回归(Ridge)和套索回归(Lasso)</h1>
            
                <div class="post-meta">
                    <br>
                    
                        作者: <a itemprop="author" rel="author" href="/">&nbsp;&nbsp;Anjhon</a>
                    

                    
                        <p class="post-time">
                        发表: <a href="#">&nbsp;&nbsp;2020-03-10</a>
                        </p>
                    
                    
                        <p class="post-category">
                    分类:
                            
                                <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">&nbsp;&nbsp;机器学习</a>
                            
                            </p>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="一-拟合"><a href="#一-拟合" class="headerlink" title="一: 拟合"></a>一: 拟合</h2><h3 id="一-过拟合与欠拟合"><a href="#一-过拟合与欠拟合" class="headerlink" title="(一): 过拟合与欠拟合"></a>(一): 过拟合与欠拟合</h3><p><strong>机器学习中一个重要的话题便是模型的泛化能力，泛化能力强的模型才是好模型</strong>，对于训练好的模型，若在训练集表现差，不必说在测试集表现同样会很差，这可能是欠拟合导致；若模型在训练集表现非常好，却在测试集上差强人意，则这便是过拟合导致的; 过拟合与欠拟合也可以用 Bias 与 Variance 的角度来解释，<strong>欠拟合会导致高 Bias; 过拟合会导致高 Variance ，所以模型需要在 Bias 与 Variance 之间做出一个权衡</strong></p>
<p><strong>Bias 即为模型的期望输出与其真实输出之间的差异</strong>；</p>
<p><strong>Variance 刻画了不同训练集得到的模型的输出与这些模型期望输出的差异</strong>。</p>
<p>一般在模型效果差的第一个想法是增多数据，其实增多数据并不一定会有更好的结果，因为<strong>欠拟合时增多数据往往导致效果更差，而过拟合时增多数据会导致 Gap 的减小，效果不会好太多</strong>，所以当模型效果很差时，应该检查模型是否处于欠拟合或者过拟合的状态，而不要一味的增多数据量，关于过拟合与欠拟合，这里给出几个解决方法。</p>
<h3 id="二-常用解决办法"><a href="#二-常用解决办法" class="headerlink" title="(二): 常用解决办法"></a>(二): 常用解决办法</h3><p><strong>(1)解决欠拟合的方法：</strong></p>
<p>1、增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;</p>
<p>2、尝试非线性模型，比如核SVM 、决策树、DNN等模型;</p>
<p>3、如果有正则项可以调小正则项参数 $\lambda$;</p>
<p>4、Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.</p>
<p><strong>(2)解决过拟合的方法：</strong></p>
<p>1、交叉检验，通过交叉检验得到较优的模型参数;</p>
<p>2、特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间;</p>
<p>3、正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择;</p>
<p>4、如果有正则项则可以考虑增大正则项参数 lambda;</p>
<p>5、增加训练数据可以有限的避免过拟合;</p>
<p>6、Bagging ,将多个弱学习器Bagging 一下效果会好很多，比如随机森林等.</p>
<h2 id="二-Ridge回归-岭回归"><a href="#二-Ridge回归-岭回归" class="headerlink" title="二: Ridge回归 - 岭回归"></a>二: Ridge回归 - 岭回归</h2><h3 id="1-Ridge回归-梯度下降-在线性回归后加上L2正则项-解决过拟合问题"><a href="#1-Ridge回归-梯度下降-在线性回归后加上L2正则项-解决过拟合问题" class="headerlink" title="1: Ridge回归 - 梯度下降(在线性回归后加上L2正则项-解决过拟合问题)"></a>1: Ridge回归 - 梯度下降(在线性回归后加上L2正则项-解决过拟合问题)</h3><p><strong>损失函数:</strong><br>$$<br>J(w) = \min\limits_w||Xw-y||_2^2 + \alpha||w||_2^2<br>$$</p>
<p><strong>$$\frac{1}{m}$$表示m个样本求平均:</strong><br>$$<br>J(w) = \frac{1}{m}\sum_{i=1}^m(||X_iw-y_i||_2^2 + \alpha||w||_2^2)<br>$$</p>
<p>$$<br>J(w) = \frac{1}{m}[(Xw-y)^T(Xw-y)+\alpha w^Tw]<br>$$</p>
<p><strong>求解梯度(导数):</strong><br>$$<br>J’(w) = \frac{2}{m}[X^T(Xw-y)+\alpha w]<br>$$</p>
<p>$$<br>\nabla_wJ(w) = \frac{2}{m} [X^T(Xw - y) +\alpha w]<br>$$</p>
<p><strong>更新w:</strong><br>$$<br>w = w-\epsilon \nabla_wJ(w)<br>$$</p>
<p>$$<br>w = w -\frac{2}{m}\epsilon[X^T(Xw-y)+\alpha w]<br>$$</p>
<p>$$<br>w = w -\frac{2\epsilon}{m}  X^T(Xw-y)-\frac{2\alpha\epsilon}{m}  w<br>$$</p>
<p>$$<br>w = [w -\frac{2\epsilon}{m}  X^T(Xw-y)]-\frac{2\alpha\epsilon}{m}  w<br>$$</p>
<p>如上公式, 中括号内的公式是线性回归的更新规则, 也就是说岭回归就是在 线性回归的基础上多减了一项,$$\frac{2\alpha\epsilon}{m}  w$$, 其</p>
<p>中:</p>
<p>​        $$\alpha &gt;= 0$$缩放强度</p>
<p>​        $$\epsilon&gt;=0$$步幅</p>
<p>​        $$m&gt;0$$样本数量</p>
<p>当w是<font color = red>正数</font>时：$$\frac{2\epsilon\alpha}{m}w$$ 为正数,此时岭回归就相当于在线性回归的基础上减去一个正数, 所以<font color = red>系数w变小</font></p>
<p>当w是<font color = red>负数</font>时：$$\frac{2\epsilon\alpha}{m}w$$ 为负数,此时岭回归就相当于在线性回归的基础上减去一个负数, 所以<font color = red>系数w的绝对值变小</font></p>
<p>正则项：w变小的好处：<font color = red>防止过拟合</font></p>
<p>岭回归适用范围:</p>
<p>方程完全共线性(方程内有方程是其他方程的倍数,相当于重复方程):</p>
<ul>
<li>x+ 2y + 22 = 9</li>
<li>2x +4y + 42 = 18</li>
</ul>
<p>岭回归适用于数据中存在共线性的情况(非满秩矩阵)</p>
<h3 id="2-Ridge回归正规方程推导"><a href="#2-Ridge回归正规方程推导" class="headerlink" title="2: Ridge回归正规方程推导:"></a>2: Ridge回归正规方程推导:</h3><p>损失函数:<br>$$<br>J(w) = \min\limits_w||Xw-y||_2^2 + \alpha||w||_2^2<br>$$</p>
<p>$$<br>J(w)=(Xw-y)^T(Xw-y)+\alpha w^Tw<br>$$</p>
<p>求导:<br>$$<br>\nabla_wJ(w)=2X^TXw-2X^Ty+2\alpha w<br>$$<br>令导数为0:<br>$$<br>2X^TXw-2X^Ty+2\alpha w=0<br>$$</p>
<p>$$<br>X^TXw-X^Ty+\alpha Iw=0<br>$$</p>
<p>$$<br>(X^TX+\alpha I)w-X^Ty=0<br>$$</p>
<p>$$<br>(X^TX+\alpha I)w=X^Ty<br>$$</p>
<p>$$<br>(X^TX+\alpha I)^{-1}(X^TX+\alpha I)w=(X^TX+\alpha I)^{-1}X^Ty<br>$$</p>
<p>推导得出w:<br>$$<br>w=(X^TX+\alpha I)^{-1}X^Ty<br>$$</p>
<h3 id="3-Ridge回归和线性回归对比"><a href="#3-Ridge回归和线性回归对比" class="headerlink" title="3: Ridge回归和线性回归对比"></a>3: Ridge回归和线性回归对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, Ridge, Lasso</span><br><span class="line"><span class="comment"># 将数据一分为二</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="comment"># 加载训练数据</span></span><br><span class="line"><span class="comment"># train = pd.read_table('./zhengqi_train.txt') 和下面一行的效果相同</span></span><br><span class="line">train = pd.read_csv(<span class="string">'./zhengqi_train.txt'</span>, sep = <span class="string">'\t'</span>)</span><br><span class="line">train</span><br><span class="line"><span class="comment"># 加载测试数据</span></span><br><span class="line">test = pd.read_table(<span class="string">'./zhengqi_test.txt'</span>)</span><br><span class="line">test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练数据分乘特征值和目标值</span></span><br><span class="line"><span class="comment"># 特征, 影响目标值的因素</span></span><br><span class="line">X = train.iloc[:, :<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 目标值</span></span><br><span class="line">y = train[<span class="string">'target'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 算法评估, 将上面的数据分成两份,一部分用来训练, 一部分用来测试</span></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用普通线性回归模型</span></span><br><span class="line">linear = LinearRegression()</span><br><span class="line">linear.fit(X_train, y_train)</span><br><span class="line">y_ = linear.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)   <span class="comment"># 均方误差</span></span><br><span class="line"><span class="string">'''0.11713370444738197'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性模型预测测试数据</span></span><br><span class="line">y_commit = linear.predict(test)</span><br><span class="line"><span class="comment"># 保存数据到本地</span></span><br><span class="line">s = pd.Series(y_commit)</span><br><span class="line">s.to_csv(<span class="string">'./linear_result.txt'</span>, index=<span class="literal">False</span>, header = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用岭回归模型</span></span><br><span class="line">ridge = Ridge(alpha=<span class="number">256</span>)   <span class="comment"># alpha值</span></span><br><span class="line">ridge.fit(X_train, y_train)</span><br><span class="line">y_ = ridge.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)</span><br><span class="line"><span class="string">'''0.13427749653218798'''</span></span><br><span class="line"></span><br><span class="line">y_commit = ridge.predict(test)</span><br><span class="line">pd.Series(y_commit).to_csv(<span class="string">'./ridge_result.txt'</span>, index=<span class="literal">False</span>, header = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><font color=red>将生成的数据上传到阿里天池,与实际数据对比,计算均方误差时, 使用岭回归模型得到的数据比使用线性回归模型得到的数据的均方误差要小,说明对该组数据,岭回归效果更好</font></p>
<h2 id="三-lasso回归-套索回归"><a href="#三-lasso回归-套索回归" class="headerlink" title="三: lasso回归 - 套索回归"></a>三: lasso回归 - 套索回归</h2><h3 id="1-lasso回归-梯度下降-在线性回归后加上L1正则项-解决过拟合问题"><a href="#1-lasso回归-梯度下降-在线性回归后加上L1正则项-解决过拟合问题" class="headerlink" title="1: lasso回归 - 梯度下降(在线性回归后加上L1正则项-解决过拟合问题)"></a>1: lasso回归 - 梯度下降(在线性回归后加上L1正则项-解决过拟合问题)</h3><p><strong>罗斯回归方程:</strong><br>$$<br>\min\limits_w \frac{1}{2n_{samples}}||Xw-y||_2^2+\alpha ||w||_1<br>$$<br><strong>方程转换:</strong><br>$$<br>J(w)=||Xw-y||_2^2+\alpha ||w||_1<br>$$<br>向量的1范数: 取绝对值的最大值</p>
<p>由于求导时方程中不能有绝对值符号, 所以分情况讨论: w是正数或者为负数</p>
<p><strong>求导:</strong><br>$$<br>\nabla_wJ(w)=2X^TXw-2X^Ty+\alpha sgn(w)<br>$$<br>sgn(w)是符号表示函数: sgn(w)代表着w&gt;0那么sgn(w)=+1;如果w&lt;0那么sgn(W)=-1</p>
<p><strong>梯度下降中系数w的更新规则:</strong><br>$$<br>w = w - \epsilon \nabla_wJ(w)<br>$$</p>
<p>$$<br>w = w - \epsilon(X^TXw-X^Ty)-\epsilon \alpha sgn(w)<br>$$</p>
<p>$$<br>w = [w - \epsilon(X^TXw-X^Ty)]-\epsilon \alpha sgn(w)<br>$$</p>
<p>当w为正时候sgn(w) =+1,直接去掉减去入所以正的w变小了</p>
<p>当w为负时候sgn(w)=-1,负号变成了正号加上了入,负数w取向零</p>
<p>Lasso回归系数可以缩减到0,岭回归不可以</p>
<p>系数(权重)变成0了,说明:可有可无,属性不重要</p>
<h3 id="2-lasso回归与岭回归和线性回归对比"><a href="#2-lasso回归与岭回归和线性回归对比" class="headerlink" title="2: lasso回归与岭回归和线性回归对比"></a>2: lasso回归与岭回归和线性回归对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, Ridge, Lasso</span><br><span class="line"><span class="comment"># 将数据一分为二</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="comment"># 加载训练数据</span></span><br><span class="line"><span class="comment"># train = pd.read_table('./zhengqi_train.txt') 和下面一行的效果相同</span></span><br><span class="line">train = pd.read_csv(<span class="string">'./zhengqi_train.txt'</span>, sep = <span class="string">'\t'</span>)</span><br><span class="line">train</span><br><span class="line"><span class="comment"># 加载测试数据</span></span><br><span class="line">test = pd.read_table(<span class="string">'./zhengqi_test.txt'</span>)</span><br><span class="line">test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练数据分乘特征值和目标值</span></span><br><span class="line"><span class="comment"># 特征, 影响目标值的因素</span></span><br><span class="line">X = train.iloc[:, :<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 目标值</span></span><br><span class="line">y = train[<span class="string">'target'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 算法评估, 将上面的数据分成两份,一部分用来训练, 一部分用来测试</span></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用普通线性回归模型</span></span><br><span class="line">linear = LinearRegression()</span><br><span class="line">linear.fit(X_train, y_train)</span><br><span class="line">y_ = linear.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)   <span class="comment"># 均方误差</span></span><br><span class="line"><span class="string">'''0.11713370444738197'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性模型预测测试数据</span></span><br><span class="line">y_commit = linear.predict(test)</span><br><span class="line"><span class="comment"># 保存数据到本地</span></span><br><span class="line">s = pd.Series(y_commit)</span><br><span class="line">s.to_csv(<span class="string">'./linear_result.txt'</span>, index=<span class="literal">False</span>, header = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用岭回归模型</span></span><br><span class="line">ridge = Ridge(alpha=<span class="number">256</span>)   <span class="comment"># alpha值</span></span><br><span class="line">ridge.fit(X_train, y_train)</span><br><span class="line">y_ = ridge.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)</span><br><span class="line"><span class="string">'''0.13427749653218798'''</span></span><br><span class="line"></span><br><span class="line">y_commit = ridge.predict(test)</span><br><span class="line">pd.Series(y_commit).to_csv(<span class="string">'./ridge_result.txt'</span>, index=<span class="literal">False</span>, header = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用lasso回归模型</span></span><br><span class="line">lasso = Lasso(alpha=<span class="number">256</span>)</span><br><span class="line">lasso.fit(X_train, y_train)</span><br><span class="line">y_ = lasso.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)</span><br><span class="line"><span class="string">'''0.9351911263395224'''</span></span><br><span class="line"></span><br><span class="line">y_commit = lasso.predict(test)</span><br><span class="line">pd.Series(y_commit).to_csv(<span class="string">'./lasso_result.txt'</span>, index=<span class="literal">False</span>, header = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><font color=red>将生成的数据上传到阿里天池,与实际数据对比,计算均方误差时, 使用lasso回归模型得到的数据比使用岭回归模型和线性回归模型得到的数据的均方误差要小,说明对该组数据,lasso回归效果较好好</font></p>
<p><font color=green>套索回归适用于稀松矩阵(大部分系数是0)</font></p>
<h2 id="四-Elastic-Net-弹性网络回归"><a href="#四-Elastic-Net-弹性网络回归" class="headerlink" title="四: Elastic-Net  -  弹性网络回归"></a>四: Elastic-Net  -  弹性网络回归</h2><p><strong>弹性网络回归方程:</strong><br>$$<br>\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha \rho ||w||_1 +<br>\frac{\alpha(1-\rho)}{2} ||w||_2 ^ 2}<br>$$</p>
<p><strong>使用弹性网络回归预测工业蒸汽量:(在线性回归后加L1, L2正则项来解决过拟合问题)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># ElasticNetCV 交叉验证(可以一次传递多个参数, 模型挑选合适的)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, Ridge, ElasticNet, ElasticNetCV</span><br><span class="line"><span class="comment"># 将数据一分为二</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="comment"># 加载训练数据</span></span><br><span class="line"><span class="comment"># train = pd.read_table('./zhengqi_train.txt') 和下面一行的效果相同</span></span><br><span class="line">train = pd.read_csv(<span class="string">'./zhengqi_train.txt'</span>, sep = <span class="string">'\t'</span>)</span><br><span class="line">train</span><br><span class="line"><span class="comment"># 加载测试数据</span></span><br><span class="line">test = pd.read_table(<span class="string">'./zhengqi_test.txt'</span>)</span><br><span class="line">test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练数据分乘特征值和目标值</span></span><br><span class="line"><span class="comment"># 特征, 影响目标值的因素</span></span><br><span class="line">X = train.iloc[:, :<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 目标值</span></span><br><span class="line">y = train[<span class="string">'target'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 算法评估, 将上面的数据分成两份,一部分用来训练, 一部分用来测试</span></span><br><span class="line"><span class="comment"># random_state = 1024 ; 种子固定,当数值固定时,生成的随机数是固定的</span></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ElasticNetCV可以筛选多个alpha中最好的一个</span></span><br><span class="line">model = ElasticNetCV(l1_ratio=<span class="number">0.05</span>, alphas=[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">5.0</span>, <span class="number">10.0</span>])</span><br><span class="line">model.fit(X, y)</span><br><span class="line">y_ = model.predict(X_validation)</span><br><span class="line">mean_squared_error(y_validation,y_)</span><br><span class="line"><span class="string">'''0.10872462328271233'''</span></span><br><span class="line"></span><br><span class="line">model.alpha_   <span class="comment"># 返回选择的alpha值</span></span><br><span class="line"></span><br><span class="line">result = model.predict(test)</span><br><span class="line">pd.Series(result).to_csv(<span class="string">'./elastic.txt'</span>, index=<span class="literal">False</span>, header=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>







        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>文章作者:</span>
                        <span>Anjhon</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>文章地址:</span>
                        <span><a href="https://anjhon1994.github.io/2020/03/10/sklearn%20-%20%E5%B2%AD%E5%9B%9E%E5%BD%92(Ridge)%E5%92%8C%E5%A5%97%E7%B4%A2%E5%9B%9E%E5%BD%92(Lasso)/">sklearn - 岭回归(Ridge)和套索回归(Lasso)</a></span>
                    </p>
                
                
                
                     <p class="copyright-item">
                         <span>灵魂拷问:</span>
                         <span>Do you believe in <strong>DESTINY<strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">✓ 机器学习</a>
                    
                        <a href="/tags/%E5%9F%BA%E7%A1%80/">✓ 基础</a>
                    
                        <a href="/tags/sklearn/">✓ sklearn</a>
                    
                        <a href="/tags/Lasso%E5%9B%9E%E5%BD%92/">✓ Lasso回归</a>
                    
                        <a href="/tags/Ridge%E5%9B%9E%E5%BD%92/">✓ Ridge回归</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/03/13/Logistic%20-%20%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92(%E5%AF%B9%E6%95%B0%E5%9B%9E%E5%BD%92)%20-%20%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/">sklearn - 逻辑斯蒂回归(Logistic)</a>
            
            
            <a class="next" rel="next" href="/2020/03/06/sklearn%20-%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92(%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)/">sklearn - 线性回归(正规方程与梯度下降)</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Anjhon | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/ Relative)","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":180,"height":350},"mobile":{"show":false},"react":{"opacityDefault":0.7}});</script></body>
</html>
