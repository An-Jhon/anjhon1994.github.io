<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">

<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Anjhon">


    <meta name="subtitle" content="小安">


    <meta name="description" content="佛系分享">



<title>手推维特比算法实现词性标注 | Anjhon</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    





    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    





    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        
		src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/unpacked/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.1.1"></head>
<body>

	
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Anjhon</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">博文</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Anjhon</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">博文</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">展开全部</a>
        <a onclick="go_top()">回到顶部</a>
        <a onclick="go_bottom()">下到底部</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "折叠起来"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "展开全部"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">手推维特比算法实现词性标注</h1>
            
                <div class="post-meta">
                    <br>
                    
                        作者: <a itemprop="author" rel="author" href="/">&nbsp;&nbsp;Anjhon</a>
                    

                    
                        <p class="post-time">
                        发表: <a href="#">&nbsp;&nbsp;2021-08-15</a>
                        </p>
                    
                    
                        <p class="post-category">
                    分类:
                            
                                <a href="/categories/NLP/">&nbsp;&nbsp;NLP</a>
                            
                            </p>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="一、词性标注简单原理"><a href="#一、词性标注简单原理" class="headerlink" title="一、词性标注简单原理"></a>一、词性标注简单原理</h1><p>现有已经标注好的词和对应的词性，作为训练数据。</p>
<p><img src="http://ww1.sinaimg.cn/large/e3ee7ad0gy1gmpmiooh8jj20s106f757.jpg" alt="维特比1.png"></p>
<p>假设给定一个句子，我们要通过构建一个维特比算法写的模型，来为这个句子标注出正确的词性。</p>
<br>


<h1 id="二、维特比算法"><a href="#二、维特比算法" class="headerlink" title="二、维特比算法"></a>二、维特比算法</h1><p><strong>维特比算法</strong>（英语：<strong>Viterbi algorithm</strong>）是一种<a href="https://zh.wikipedia.org/wiki/动态规划" target="_blank" rel="noopener">动态规划</a><a href="https://zh.wikipedia.org/wiki/算法" target="_blank" rel="noopener">算法</a>。它用于寻找最有可能产生观测事件序列的<strong>维特比路径</strong>——隐含状态序列，特别是在马尔可夫信息源上下文和隐马尔可夫模型中。术语“维特比路径”和“维特比算法”也被用于寻找观察结果最有可能解释相关的动态规划算法。例如在<a href="https://zh.wikipedia.org/w/index.php?title=统计句法分析&action=edit&redlink=1" target="_blank" rel="noopener">统计句法分析</a>中动态规划算法可以被用于发现最可能的上下文无关的派生（解析）的字符串，有时被称为“维特比分析”。</p>
<p>—— 维基百科</p>
<p>假设句子S：$S=w_1 w_2 w_3…w_n$，用 $Z$ 代表句子 $S$ 的词性，那么就可以写成：<br>$$<br>\hat Z = \underset{z}{\operatorname{argmax}} P(Z|S)<br>$$<br>解读为: 给定一个句子 $S$ , 求它最大概率的词性序列 $Z$<br>$$<br>\begin{aligned}<br>&amp; 根据贝叶斯定理可得: \\<br>&amp; \\<br>P(Z|S) &amp;= \frac{P(S|Z)·P(Z)}{P(S)}\\<br>&amp; \\<br>&amp; 又根据噪声信道模型(Noise Channel Model)可得: \\<br>&amp; \\<br>P(Z|S)<br>&amp; \propto P(S|Z)·P(Z)\\<br>&amp; = P(S_1,S_2,S_3…S_n|Z_1,Z_1,Z_3…Z_n)·P(Z_1,Z_1,Z_3…Z_n)\\<br>&amp; \\<br>&amp; 假设每个单词的 词与词性 是互相独立的, 那么:\\<br>&amp; \\<br>&amp; = P(S_1|Z_1)·P(S_2|Z_2),P(S_3|Z_3)…P(S_n|Z_n)·P(Z_1,Z_1,Z_3…Z_n)\\<br>&amp; = \prod_{i=1}^n P(S_i|Z_i)·P(Z_1,Z_1,Z_3…Z_n)\\<br>&amp; \\<br>&amp; 通过bigram模型来展开,那么:\\<br>&amp; \\<br>&amp; = \prod_{i=1}^n P(S_i|Z_i)·P(Z_1)·P(Z_2|Z_1)·P(Z_3|Z_2)…P(Z_n|Z_{n-1})\\<br>&amp; = \prod_{i=1}^n P(S_i|Z_i)·P(Z_1)·\prod_{t=2}^nP(Z_t|Z_{t-1})\\<br>&amp; \\<br>&amp; 在前面加log并展开:\\<br>&amp; \\<br>&amp; = log(\prod_{i=1}^n P(S_i|Z_i)·P(Z_1)·\prod_{t=2}^n P(Z_t|Z_{t-1}))\\<br>&amp; = \sum_{i=1}^n log(P(S_i|Z_i)) + log(P(Z_1)) + \sum_{t=2}^n log(P(Z_t|Z_{t-1}))\\<br>\end{aligned}<br>$$</p>
<p>最终得到:<br>$$<br>\hat Z = \underset{z}{\operatorname{argmax}} (\sum_{i=1}^n log(P(S_i|Z_i)) + log(P(Z_1)) + \sum_{t=2}^n log(P(Z_t|Z_{t-1})))<br>$$</p>
<p>这里的 $\hat Z$ 最终输出的是一个（概率最大的）词性序列，得到上面这个公式之后，我们就可以用维特比算法进行求解</p>
<p>由于篇幅原因，这里就不展开介绍维特比算法了。</p>
<p>这里有更好的文章：<a href="https://www.zhihu.com/question/20136144/answer/763021768" target="_blank" rel="noopener">如何通俗地讲解 viterbi 算法？</a> </p>
<blockquote>
<p>$A = P(S_i|Z_i)$ 表示给定一个词性, 出现某个单词的概率</p>
<p>$\pi = P(Z_1)$ 表示该词性出现在句首的概率</p>
<p>$B = P(Z_t|Z_{t-1})$ 表示句子中出现 $Z_{t-1}$ 之后出现 $Z_t$ 的概率(词性转移的概率)</p>
</blockquote>
<p>以上三个参数都可以在训练数据中可以统计出来</p>
<p>假设, 训练数据中单词的个数(词典的长度)为M, 词性的个数为N, 那么:</p>
<p>A 是一个 M*N的矩阵; $\pi$ 是一个长度为N的向量, B 是一个N*N的矩阵</p>
<p>接下来就是愉快的代码时间了</p>
<br>


<h1 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h1><h2 id="1-建立单词和词性的map"><a href="#1-建立单词和词性的map" class="headerlink" title="1: 建立单词和词性的map"></a>1: 建立单词和词性的map</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立map，以便后面在更新矩阵和向量时统计次数，并求出概率</span></span><br><span class="line">tag2id, id2tag = &#123;&#125;, &#123;&#125;</span><br><span class="line">word2id, id2word = &#123;&#125;, &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'traindata.txt'</span>):</span><br><span class="line">    items = line.split(<span class="string">'/'</span>)</span><br><span class="line">    word, tag = items[<span class="number">0</span>], items[<span class="number">1</span>].rstrip()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word2id:</span><br><span class="line">        word2id[word] = len(word2id)</span><br><span class="line">        id2word[len(id2word)] = word</span><br><span class="line">    <span class="keyword">if</span> tag <span class="keyword">not</span> <span class="keyword">in</span> tag2id:</span><br><span class="line">        tag2id[tag] = len(tag2id)</span><br><span class="line">        id2tag[len(id2tag)] = tag</span><br><span class="line">        </span><br><span class="line">M = len(word2id)   <span class="comment"># 词典大小</span></span><br><span class="line">N = len(tag2id)   <span class="comment"># 词性个数</span></span><br><span class="line">print(M, N)</span><br></pre></td></tr></table></figure>



<h2 id="2-代码实现计算参数A-pi-B"><a href="#2-代码实现计算参数A-pi-B" class="headerlink" title="2: 代码实现计算参数A, $\pi$ , B"></a>2: 代码实现计算参数A, $\pi$ , B</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化参数</span></span><br><span class="line">pi = np.zeros(N)</span><br><span class="line">A = np.zeros((N, M))</span><br><span class="line">B = np.zeros((N, N))</span><br><span class="line"></span><br><span class="line">prev_tag = <span class="string">''</span>   <span class="comment"># 用来保存上一个词的词性</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'traindata.txt'</span>):</span><br><span class="line">    items = line.split(<span class="string">'/'</span>)</span><br><span class="line">    wordid, tagid = word2id[items[<span class="number">0</span>]], tag2id[items[<span class="number">1</span>].rstrip()]   <span class="comment"># 获取词和词性对应的id</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 先统计pi A B对应位置的次数</span></span><br><span class="line">    <span class="keyword">if</span> prev_tag == <span class="string">''</span>:   <span class="comment"># 判断当前单词是否为句子的开始</span></span><br><span class="line">        pi[tagid] += <span class="number">1</span>   </span><br><span class="line">        A[tagid][wordid] += <span class="number">1</span>   </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        A[tagid][wordid] += <span class="number">1</span></span><br><span class="line">        B[tag2id[prev_tag]][tagid] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> items[<span class="number">0</span>] == <span class="string">'.'</span>:   <span class="comment"># 如果当前单词为句号，那么更新prev_tag的状态，以便下次循环判断是否为句子的开始</span></span><br><span class="line">        prev_tag = <span class="string">''</span></span><br><span class="line">    <span class="keyword">else</span>:   <span class="comment"># 否则就记录当前词的词性</span></span><br><span class="line">        prev_tag = items[<span class="number">1</span>].rstrip()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment"># 将次数转换成概率</span></span><br><span class="line">pi = pi / sum(pi)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(N):   </span><br><span class="line">    A[i] = A[i] / sum(A[i])   <span class="comment"># 求矩阵中每个数在每一行的占比（概率）</span></span><br><span class="line">    B[i] = B[i] / sum(B[i])</span><br></pre></td></tr></table></figure>



<h2 id="3-建立模型"><a href="#3-建立模型" class="headerlink" title="3: 建立模型"></a>3: 建立模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(v)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> v == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> np.log(v + <span class="number">0.00000001</span>)   <span class="comment"># 平滑操作</span></span><br><span class="line">    <span class="keyword">return</span> np.log(v)        </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viterbi</span><span class="params">(x, pi, A, B)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    x: 需要预测词性的句子</span></span><br><span class="line"><span class="string">    pi: 词性出现句首的概率</span></span><br><span class="line"><span class="string">    A：给定词性，每个单词出现的概率</span></span><br><span class="line"><span class="string">    B：词性质检转换的概率（上个单词的词性为a，下个单词的词性为b的概率）</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x =[word2id[word] <span class="keyword">for</span> word <span class="keyword">in</span> x.split(<span class="string">' '</span>)]   <span class="comment"># 输入为因为句子，直接用空格切割；如果为中文，则需要分词</span></span><br><span class="line">    T = len(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义一个二维数组dp，dp[i][j]表示从第一个单词到第i个单词,第j个词性的最优路径</span></span><br><span class="line">    dp = np.zeros([T,N])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义一个二维数组ptr，记录当前dp节点最好路径得分 是由上一次哪一个词性计算得来的</span></span><br><span class="line">    ptr = np.array([[<span class="number">0</span> <span class="keyword">for</span> y <span class="keyword">in</span> range(N)] <span class="keyword">for</span> x <span class="keyword">in</span> range(T)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算dp 第一例（第一个单词）在每个词性下的路径值</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">        dp[<span class="number">0</span>][j] = log(pi[j]) + log(A[j][x[<span class="number">0</span>]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算第二个词往后的所有路径得分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, T):   <span class="comment"># 每个单词</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(N):   <span class="comment"># 每个词性</span></span><br><span class="line">            dp[i][j] = <span class="number">-999999</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(N):   <span class="comment"># 上一个词的词性</span></span><br><span class="line">                </span><br><span class="line">                score = dp[i<span class="number">-1</span>][k] + log(A[j][x[i]]) + log(B[k][j])   <span class="comment"># 计算每个路径的值</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> score &gt; dp[i][j]:</span><br><span class="line">                    dp[i][j] = score   <span class="comment"># 获取最优值,填到dp中</span></span><br><span class="line">                    ptr[i][j] = k   <span class="comment"># 记录最优值路径</span></span><br><span class="line">                                </span><br><span class="line">    best_seq = [<span class="number">0</span>]*T</span><br><span class="line">    best_seq[T<span class="number">-1</span>] = np.argmax(dp[T<span class="number">-1</span>])  <span class="comment"># 求出最后一个单词 的最大可能性 的词性 的下标</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(T<span class="number">-2</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        best_seq[i] = ptr[i+<span class="number">1</span>][best_seq[i+<span class="number">1</span>]]   <span class="comment"># 获取被预测句子的每个词的最优词性的id</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(best_seq)):</span><br><span class="line">        print(id2tag[best_seq[i]])   <span class="comment"># 将最优词性的id转为对应的词性</span></span><br></pre></td></tr></table></figure>



<h2 id="4-测试"><a href="#4-测试" class="headerlink" title="4: 测试"></a>4: 测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="string">"Social Security number , passport number and details about the services provided for the payment"</span></span><br><span class="line">viterbi(x, pi, A, B)</span><br></pre></td></tr></table></figure>



<figure class="highlight django"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="template-tag">&#123;% <span class="name">btn</span> #, 文本 &amp; 标题,, 标题 %&#125;</span></span><br></pre></td></tr></table></figure>


        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>文章作者:</span>
                        <span>Anjhon</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>文章地址:</span>
                        <span><a href="https://anjhon1994.github.io/2021/08/15/NLP/%E6%89%8B%E5%86%99%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8/">手推维特比算法实现词性标注</a></span>
                    </p>
                
                
                
                     <p class="copyright-item">
                         <span>灵魂拷问:</span>
                         <span>Do you believe in <strong>DESTINY<strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>文章标签:</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8/">▼ 词性标注</a>
                    
                        <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">▼ 自然语言处理</a>
                    
                        <a href="/tags/NLP/">▼ NLP</a>
                    
                        <a href="/tags/viterbi/">▼ viterbi</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">【返回上一层】</a>
                <span>· </span>
                <a href="/">【去往首页】</a>
            </div>
        </section>
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/2020/04/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95/">下一篇：集成算法</a>
            
			<br>

        </section>


		<br>
		
		
			<span>留下你的痕迹😀</span>
			<section id="comments" class="comments">
			  <style>
				.comments{margin:10px;padding:10px;background:#fff;bordercolor:0,0,0}
				@media screen and (max-width:900px){.comments{margin:auto;padding:20px;background:#fff;bordercolor:0,0,0}}
			  </style>
			  <div id="vcomment" class="comment"></div> 
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script src="https://cdnjs.loli.net/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
    var notify = 'false' == true ? true : false;
    var verify = 'false' == true ? true : false;
    new Valine({
        av: AV,
        el: '#vcomment',
        notify: notify,
        app_id: "d8Xy9CoRkV8wkjgNsf6IRqfe-gzGzoHsz",
        app_key: "ePiIX7dqVFpzeKkr4T1ixiah",
        placeholder: "🎈🎈🎈 Just say say ...",
        avatar:"robohash",

		
		
		
    });
</script>

			</section>
		
		


    </article>
</div>





			
        </div>
		
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 
		Anjhon | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a>
		
		
		
		
		</span>
    </div>
</footer>

    </div>
	


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/ Relative)","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":180,"height":350},"mobile":{"show":false},"react":{"opacityDefault":0.7}});</script></body>
</html>
